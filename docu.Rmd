---
title: "problem"
author: "Luofeng Liao"
date: "March 13, 2018"
output:
  pdf_document: default
  html_document: default
---
## Easy

use `glmnet::cv.glmnet` to compute a L1-regularized linear model of the spam data in library(ElemStatLearn). 

What features are selected for the prediction function?  
```{r}
library(ElemStatLearn)
library(glmnet)

sum(is.na(spam)) # make sure data is valid
p <- 57 # Each email is represented by 57 features
n <- length(spam$spam)

set.seed(123)
class <- factor(spam$spam, labels=c(0,1)) # email = 0, spam = 1

trainIdx <- sort(sample(1:n, floor(n*0.75)))
train_class <- spam$spam[trainIdx]
train_feat <- data.matrix(spam[trainIdx,1:p])
test_class <- spam$spam[-trainIdx]
test_feat <- data.matrix(spam[-trainIdx,1:p])


logistic.fitted <- cv.glmnet(train_feat,train_class, 
                             family = "binomial",
                             alpha=1)

plot(logistic.fitted)
coefficients <- coef(logistic.fitted, s="lambda.1se")
names(coefficients[which(coefficients != 0),])

```
To reduce complexity of the model, I choose lambda one SE away from the lambda.min.


What is the test error and test AUC of the learned model? 
```{r}
library(pROC)
test_pred <- predict(logistic.fitted, test_feat, s="lambda.min",type="class")

#convert to 0(spam) and 1(email)
test_pred[0:100]
tmp <- rep(0,length(test_class))
tmp[test_pred == 'spam'] = 1


roc_lasso <- roc(test_class, tmp,ci=T)
plot(roc_lasso)
auc(roc_lasso)

const_pre <- rep(0,length(test_class))
roc_const < - roc(test_class, const_pre,ci=T)
plot(roc_const)
auc(roc_const)
```
Is it significantly better than the trivial model which predicts the most frequent class in the training data? Answer these questions by using K-fold cross-validation in the spam data.

Yes, it is.

# Medium

